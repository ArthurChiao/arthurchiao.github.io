---
layout    : post
title     : "[è¯‘][è®ºæ–‡] P5 paper | ç”¨è¯­è¨€æ¨¡å‹åšæ¨èï¼šä¸€ç§ç»Ÿä¸€çš„é¢„è®­ç»ƒã€ä¸ªæ€§åŒ–æç¤ºå’Œé¢„æµ‹èŒƒå¼ï¼ˆ2022ï¼‰"
date      : 2025-12-20
lastupdate: 2025-12-20
categories: ai transformer
---

### è¯‘è€…åº

æœ¬æ–‡ç¿»è¯‘è‡ª 2022 å¹´ RecSys å¤§ä¼šçš„ä¸€ç¯‡è®ºæ–‡
[Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt & Predict Paradigm (P5)](https://arxiv.org/abs/2203.13366)ã€‚

<p align="center"><img src="/assets/img/p5-paper/fig-1.png" width="100%" height="100%"></p>
<p align="center">
Figure 1: P5 pretrains on an encoderâ€“decoder Transformer model that takes in textual inputs and produces target responses.
</p>

<p align="center"><img src="/assets/img/p5-paper/fig-3.png" width="100%" height="100%"></p>
<p align="center">å›¾ 3ï¼šP5 æ¶æ„ç¤ºæ„å›¾ã€‚</p>


æ°´å¹³åŠç»´æŠ¤ç²¾åŠ›æ‰€é™ï¼Œè¯‘æ–‡ä¸å…å­˜åœ¨é”™è¯¯æˆ–è¿‡æ—¶ä¹‹å¤„ï¼Œå¦‚æœ‰ç–‘é—®ï¼Œè¯·æŸ¥é˜…åŸæ–‡ã€‚
**<mark>ä¼ æ’­çŸ¥è¯†ï¼Œå°Šé‡åŠ³åŠ¨ï¼Œå¹´æ»¡åå…«å‘¨å²ï¼Œè½¬è½½è¯·æ³¨æ˜<a href="https://arthurchiao.art">å‡ºå¤„</a></mark>**ã€‚

ä»¥ä¸‹æ˜¯è¯‘æ–‡ã€‚

----

* TOC
{:toc}

----

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
      },
    "HTML-CSS": {
      availableFonts: [], preferredFont: null,
      webFont: "Neo-Euler",
      mtextFontInherit: true
    },
    TeX: {
      extensions: ["color.js"],
      Macros: {
        lgc: ["{\\color{my-light-green} #1}", 1],
        gc: ["{\\color{my-green} #1}", 1],
        lrc: ["{\\color{my-light-red} #1}", 1],
        rc: ["{\\color{my-red} #1}", 1],
        lbc: ["{\\color{my-light-blue} #1}", 1],
        bc: ["{\\color{my-blue} #1}", 1],
        kc: ["{\\color{my-gray} #1}", 1],
        loc: ["{\\color{my-light-orange} #1}", 1],
        oc: ["{\\color{my-orange} #1}", 1],

        a: ["\\mathbf a"],
        A: ["\\mathbf A"],
        b: ["\\mathbf b"],
        B: ["\\mathbf B"],
        c: ["\\mathbf c"],
        C: ["\\mathbf C"],
        d: ["\\mathbf d"],
        D: ["\\mathbf D"],
        E: ["\\mathbf E"],
        I: ["\\mathbf I"],
        L: ["\\mathbf L"],
        m: ["\\mathbf m"],
        M: ["\\mathbf M"],
        r: ["\\mathbf r"],
        s: ["\\mathbf s"],
        t: ["\\mathbf t"],
        S: ["\\mathbf S"],
        x: ["\\mathbf x"],
        z: ["\\mathbf z"],
        v: ["\\mathbf v"],
        y: ["\\mathbf y"],
        k: ["\\mathbf k"],
        bp: ["\\mathbf p"],
        P: ["\\mathbf P"],
        q: ["\\mathbf q"],
        Q: ["\\mathbf Q"],
        r: ["\\mathbf r"],
        R: ["\\mathbf R"],
        Sig: ["\\mathbf \\Sigma"],
        t: ["\\mathbf t"],
        T: ["\\mathbf T"],
        e: ["\\mathbf e"],
        X: ["\\mathbf X"],
        u: ["\\mathbf u"],
        U: ["\\mathbf U"],
        v: ["\\mathbf v"],
        V: ["\\mathbf V"],
        w: ["\\mathbf w"],
        W: ["\\mathbf W"],
        Y: ["\\mathbf Y"],
        z: ["\\mathbf z"],
        Z: ["\\mathbf Z"],
        p: ["\\,\\text{.}"],
        tab: ["\\hspace{0.7cm}"],

        sp: ["^{\\small\\prime}"],


        mR: ["{\\mathbb R}"],
        mC: ["{\\mathbb C}"],
        mN: ["{\\mathbb N}"],
        mZ: ["{\\mathbb Z}"],

        deg: ["{^\\circ}"],


        argmin: ["\\underset{#1}{\\text{argmin}}", 1],
        argmax: ["\\underset{#1}{\\text{argmax}}", 1],

        co: ["\\;\\text{cos}"],
        si: ["\\;\\text{sin}"]
      }
    }
    });

    MathJax.Hub.Register.StartupHook("TeX color Ready", function() {
       MathJax.Extension["TeX/color"].colors["my-green"] = '#677d00';
       MathJax.Extension["TeX/color"].colors["my-light-green"] = '#acd373';
       MathJax.Extension["TeX/color"].colors["my-red"] = '#b13e26';
       MathJax.Extension["TeX/color"].colors["my-light-red"] = '#d38473';
       MathJax.Extension["TeX/color"].colors["my-blue"] = '#306693';
         MathJax.Extension["TeX/color"].colors["my-light-blue"] = '#73a7d3';
         MathJax.Extension["TeX/color"].colors["my-gray"] = '#999';
         MathJax.Extension["TeX/color"].colors["my-orange"] = '#E69500';
         MathJax.Extension["TeX/color"].colors["my-light-orange"] = '#FFC353';


  });
</script>

<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js">
</script>

# æ‘˜è¦

é•¿æœŸä»¥æ¥ï¼Œä¸åŒçš„æ¨èä»»åŠ¡é€šå¸¸éœ€è¦<strong><mark>é’ˆå¯¹ç‰¹å®šä»»åŠ¡</mark></strong>è®¾è®¡
<strong><mark>æ¶æ„ä¸è®­ç»ƒç›®æ ‡</mark></strong> (task-specific architectures and training objectives)ã€‚
è¿™å¯¼è‡´<strong><mark>éš¾ä»¥å°†å­¦ä¹ åˆ°çš„çŸ¥è¯†ä¸è¡¨å¾ä»ä¸€ä¸ªä»»åŠ¡è¿ç§»åˆ°å¦ä¸€ä¸ªä»»åŠ¡</mark></strong>ï¼Œ
ä»è€Œ<strong><mark>é™åˆ¶äº†ç°æœ‰æ¨èæ–¹æ³•çš„æ³›åŒ–èƒ½åŠ›</mark></strong>ã€‚
ä¾‹å¦‚ï¼Œä¸€ä¸ªåºåˆ—æ¨èæ¨¡å‹ (sequential recommendation) å¾ˆéš¾è¢«åº”ç”¨æˆ–è¿ç§»åˆ°è¯„è®ºç”Ÿæˆ (review generation) ä»»åŠ¡ä¸­ã€‚

è€ƒè™‘åˆ°<strong><mark>è¯­è¨€å‡ ä¹å¯ä»¥æè¿°ä»»ä½•äº‹ç‰©</mark></strong>ï¼Œ
è€Œä¸”è¯­è¨€åŸºç¡€æ˜¯ä¸€ç§è¡¨å¾å„ç§é—®é¢˜æˆ–ä»»åŠ¡çš„å¼ºå¤§åª’ä»‹ï¼Œæœ¬æ–‡æå‡ºä¸€ç§çµæ´»ã€ç»Ÿä¸€çš„<strong><mark>æ–‡æœ¬åˆ°æ–‡æœ¬</mark></strong>èŒƒå¼æ¥è§£å†³ä»¥ä¸Šé—®é¢˜ â€”â€”
è¿™ç§èŒƒå¼æˆ‘ä»¬ç§°ä¸º â€œ<strong><mark><code>Pretrain, Personalized Prompt, and Predict Paradigm</code></mark></strong>â€ (é¢„è®­ç»ƒã€ä¸ªæ€§åŒ–æç¤ºä¸é¢„æµ‹èŒƒå¼)ï¼Œç¼©å†™ä¸º P5ã€‚
å®ƒå°†å„ç±»æ¨èä»»åŠ¡ç»Ÿä¸€åœ¨ä¸€ä¸ªå…±äº«æ¡†æ¶ä¸­ï¼Œ

* åœ¨ P5 ä¸­ï¼Œ<strong><mark>æ‰€æœ‰æ•°æ®</mark></strong>
ï¼ˆuser-item interactions, user descriptions, item metadata, user reviews ç­‰ï¼‰<strong><mark>éƒ½è¢«è½¬æ¢ä¸ºç»Ÿä¸€çš„è‡ªç„¶è¯­è¨€åºåˆ—</mark></strong>ã€‚
* <strong><mark>è‡ªç„¶è¯­è¨€</mark></strong>æ‰€è•´å«çš„ä¸°å¯Œä¿¡æ¯æœ‰åŠ©äº P5 <strong><mark>æ•è·æ›´æ·±å±‚çš„è¯­ä¹‰</mark></strong>ï¼Œä»è€Œå®ç°<strong><mark>ä¸ªæ€§åŒ–æ¨è</mark></strong>ã€‚

å…·ä½“è€Œè¨€ï¼ŒP5 åœ¨é¢„è®­ç»ƒé˜¶æ®µé€šè¿‡<strong><mark>ç›¸åŒçš„è¯­è¨€å»ºæ¨¡ç›®æ ‡</mark></strong>å­¦ä¹ <strong><mark>ä¸åŒä»»åŠ¡</mark></strong>ï¼Œ
ä»è€Œæˆä¸ºå„ç±»ä¸‹æ¸¸æ¨èä»»åŠ¡çš„åŸºç¡€æ¨¡å‹ã€‚

* P5 ä¸ä»…èƒ½è½»æ¾ä¸å…¶ä»–æ¨¡æ€ä¿¡æ¯èåˆï¼Œè¿˜èƒ½åŸºäºæç¤ºå®ç°æŒ‡ä»¤é©±åŠ¨çš„æ¨èã€‚
* P5 å°†æ¨èç³»ç»Ÿä»æµ…å±‚æ¨¡å‹ã€æ·±åº¦æ¨¡å‹æ¨è¿›è‡³å¤§æ¨¡å‹é˜¶æ®µï¼Œå¹¶å°†ä»¥<strong><mark>é€šç”¨æ¨èå¼•æ“</mark></strong>çš„å½¢å¼å½»åº•é©æ–°æ¨èç³»ç»Ÿçš„æŠ€æœ¯å½¢æ€ã€‚
* é€šè¿‡ä¸ºä¸åŒç”¨æˆ·è‡ªé€‚åº”ç”Ÿæˆä¸ªæ€§åŒ–æç¤ºï¼ŒP5 èƒ½å¤Ÿä»¥é›¶æ ·æœ¬æˆ–å°‘æ ·æœ¬æ–¹å¼è¿›è¡Œé¢„æµ‹ï¼Œå¤§å¹…å‡å°‘äº†å¯¹å¤§é‡å¾®è°ƒçš„ä¾èµ–ã€‚

æˆ‘ä»¬åœ¨å¤šä¸ªæ¨èåŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†å®éªŒï¼ŒéªŒè¯äº† P5 çš„æœ‰æ•ˆæ€§ï¼Œç›¸å…³ä»£ç å’Œæ¨¡å‹ä¹Ÿå·²ç»å¼€æºï¼š

* [github.com/jeykigung/P5](https://github.com/jeykigung/P5) å¼€æºäº†æºä»£ç ã€æ•°æ®é›†ã€æç¤ºè¯åŠé¢„è®­ç»ƒçš„ P5 æ¨¡å‹ã€‚
* [huggingface.co/makitanikaze/P5](https://huggingface.co/makitanikaze/P5) æ¨¡å‹ã€‚

# 1 å¼•è¨€

è¿‡å»å‡ åå¹´ï¼Œæ¨èç³»ç»Ÿå–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œå¹¶åœ¨äººä»¬çš„æ—¥å¸¸ç”Ÿæ´»ä¸­å‘æŒ¥ç€é‡è¦ä½œç”¨ã€‚
è€Œç°åœ¨ï¼Œæ¨èç³»ç»Ÿåœ¨æœç€ç‰¹å¾æ›´å¤šæ ·æ€§ã€åº”ç”¨åœºæ™¯æ›´å¹¿æ³›çš„ç»¼åˆç³»ç»Ÿå‘å±•ã€‚

## 1.1 ç°é˜¶æ®µæ¨èç³»ç»Ÿçš„ç‰¹ç‚¹

### ç‰¹å¾è¡¨ç¤ºå’Œå­¦ä¹ è¶Šæ¥è¶Šå¤æ‚

æ¨èç³»ç»Ÿä¸­çš„ feature engineering å’Œ learning å·²ç»ä»ç®€å•å‘å±•åˆ°å¤æ‚ã€‚

* æ—©æœŸï¼Œæ¨èç³»ç»Ÿé€šå¸¸é‡‡ç”¨ <strong><mark><code>logistic regression</code></mark>
  </strong> æˆ– <strong><mark><code>collaborative filtering</code></mark>
  </strong> [25, 35, 50, 52]ï¼Œåˆ©ç”¨ <strong><mark><code>user-item
  interaction</code></mark></strong> æ•°æ®æ¥å»ºæ¨¡ç”¨æˆ·çš„è¡Œä¸ºæ¨¡å¼ã€‚
* ä¹‹åï¼Œé€šè¿‡æ›´å¤æ‚çš„æ¨¡å‹å¦‚ factorization machines [48] å’Œ GBDT [20]ï¼Œå°† <strong>
  <mark><code>contextual features</code></mark></strong>ï¼ˆå¦‚ <strong><mark>
  <code>user profile</code></mark></strong> å’Œ <strong><mark><code>item
  metadata</code></mark></strong>ï¼‰è¿›ä¸€æ­¥æ•´åˆåˆ°ç³»ç»Ÿä¸­ã€‚
* æœ€è¿‘ï¼Œ<strong><mark><code>deep neural network models</code></mark></strong>
  [3, 5, 19, 74] ä¿ƒè¿›äº†æ›´åŠ å¤šæ ·å’Œå¤æ‚çš„ç‰¹å¾ä¹‹é—´çš„äº¤å‰ä¸ç»„åˆã€‚å› æ­¤ï¼Œä¸ä¼ ç»ŸåŸºäº
  feature engineering çš„æ–¹æ³•ç›¸æ¯”ï¼Œè¿™äº›æ¨¡å‹è·å¾—äº†æ›´å¥½çš„è¡¨ç¤ºèƒ½åŠ›ã€‚

### æ¨èä»»åŠ¡çš„ç±»å‹è¶Šæ¥è¶Šå¤šæ ·

<strong><mark>æ¨èä»»åŠ¡çš„ç±»å‹</mark></strong>ä¹Ÿè¶Šæ¥è¶Šå¤šã€‚
é™¤äº†ç»å…¸çš„ rating prediction å’ŒåŸºäº direct user-item matching çš„æ¨èä»»åŠ¡ä¹‹å¤–ï¼Œ
æœ€è¿‘çš„ç ”ç©¶æ­£åœ¨å°†èŒƒå›´æ‰©å±•åˆ°æ–°çš„ä»»åŠ¡å’Œåœºæ™¯ï¼Œå¦‚

1. sequential recommendation [21, 60, 63, 80]
2. conversational recommendation [8, 61, 76]
3. explainable recommendation [17, 31, 62, 70, 75, 77]

ç­‰ç­‰ã€‚è™½ç„¶ä¸Šè¿°æ¨èä»»åŠ¡çš„æ–¹æ³•é€šå¸¸æ˜¯å•ç‹¬æå‡ºçš„ï¼Œä½†ä¸€ä¸ªæ˜æ˜¾çš„è¶‹åŠ¿æ˜¯
<strong><mark>åˆ©ç”¨å¤šä¸ªæ¨èä»»åŠ¡æ¥è”åˆå­¦ä¹ </mark></strong> <strong><mark><code>transferable representations</code></mark></strong> [31, 56, 57, 72]ã€‚

## 1.2 ç°ä»£æ¨èç³»ç»Ÿéœ€è¦ä»€ä¹ˆ

å°½ç®¡ç°æœ‰çš„æ¨èç³»ç»Ÿå–å¾—äº†å·¨å¤§æˆåŠŸï¼Œä½†åœ¨è§£å†³å®é™…é—®é¢˜ä¸Šä»é¢ä¸´å¾ˆå¤šé—®é¢˜ï¼Œæˆ‘ä»¬è®¤ä¸ºéœ€è¦
ä¸€ä¸ªèƒ½æ”¯æŒå¤šæ ·ç‰¹å¾å’Œä¸åŒç±»å‹ä»»åŠ¡çš„ç»¼åˆæ¨èç³»ç»Ÿã€‚

æ¨èä»»åŠ¡é€šå¸¸<strong><mark>å…±äº«åŒä¸€ä¸ª userâ€“item pool</mark></strong>ï¼ˆç”¨æˆ·-ç‰©å“ä¿¡æ¯æ± ï¼‰
å¹¶<strong><mark>å…·æœ‰é‡å çš„ contextual features</mark></strong>ï¼Œ
å› æ­¤ï¼Œæˆ‘ä»¬ä»»åŠ¡<strong><mark>å°†å¤šä¸ªæ¨èä»»åŠ¡åˆå¹¶åˆ°ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ä¸­</mark></strong>æ˜¯éå¸¸æœ‰å¸Œæœ›çš„ï¼Œ
è¿™æ ·å¤šä¸ªä»»åŠ¡å¯ä»¥<strong><mark>éšå¼åœ° transfer knowledge</mark></strong>ï¼Œç›¸äº’å—ç›Šï¼Œ
å¹¶<strong><mark>æ³›åŒ–</mark></strong>åˆ°å…¶å®ƒæ²¡è§è¿‡çš„ä»»åŠ¡ã€‚

## 1.3 P5 çš„åˆ›æ–°ç‚¹

å—æœ€è¿‘ multitask prompt-based training [1, 51, 67] è¿›å±•çš„å¯å‘ï¼Œæœ¬æ–‡æå‡ºä¸€ä¸ªç»Ÿä¸€çš„èŒƒå¼ P5ã€‚
å®ƒæœ‰ä¸‰ä¸ªä¸»è¦ä¼˜åŠ¿ï¼š

1. å°†<strong><mark>æ¨èæ¨¡å‹</mark></strong>ï¼ˆè¡Œä¸ºæ¨¡å‹ï¼‰æ·±åº¦èå…¥åˆ°<strong><mark>è¯­è¨€ç¯å¢ƒ</mark></strong>ï¼ˆè¯­è¨€æ¨¡å‹ï¼‰ä¸­ã€‚

   åŸºäº personalized promptsï¼Œ<strong><mark>æ‰€æœ‰æ¨èä»»åŠ¡éƒ½è¢«é‡æ–°è¡¨è¿°ä¸º NLP ä»»åŠ¡</mark></strong>ã€‚
   ç”±äºè‡ªç„¶è¯­è¨€è¶³å¤Ÿçµæ´»å’Œå¼ºå¤§ï¼Œèƒ½å¤Ÿ<strong><mark>ç”¨æ–‡æœ¬è¡¨è¾¾å„ç§ç±»å‹çš„ç‰¹å¾</mark></strong>ï¼Œ
   å› æ­¤<strong><mark>æ— éœ€è®¾è®¡ feature-specific encoders</mark></strong>ã€‚
   é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒP5 å¯ä»¥å……åˆ†åˆ©ç”¨è®­ç»ƒè¯­æ–™åº“ä¸­ä¸°å¯Œçš„è¯­ä¹‰å’ŒçŸ¥è¯†ï¼›

    > è¯‘æ³¨ï¼š[ä» Tokenization è§†è§’çœ‹ç”Ÿæˆå¼æ¨èï¼ˆGRï¼‰è¿‘å‡ å¹´çš„å‘å±•ï¼ˆ2025ï¼‰]({% link _posts/2025-11-27-large-generative-recommendation-tokenization-perspective-notes-zh.md %})
    > <p align="center"><img src="/assets/img/large-generative-recommendation-tokenization-perspective/model-as-reflection-of-real-world.png" width="90%" height="90%"></p>

2. å°†å¤šä¸ªæ¨èä»»åŠ¡æ”¾åˆ°åŒä¸€ä¸ª text-to-text
   encoder-decoder ä¸­ï¼Œå¹¶ä½¿ç”¨<strong><mark>ç›¸åŒçš„ language modeling loss è¿›è¡Œè®­ç»ƒ</mark></strong>ï¼Œ
   è€Œä¸æ˜¯è®¾è®¡ task-specific æ¶æ„å’Œ objective functionsã€‚

   æ¢å¥è¯è¯´ï¼Œ
   P5 <strong><mark>å°†æ‰€æœ‰ personalized tasks è§†ä¸º conditional text generation é—®é¢˜</mark></strong>ï¼›

3. é€šè¿‡ instruction-based prompts è®­ç»ƒï¼ŒP5 åœ¨æ¨å¹¿åˆ°æ–°çš„ personalized prompts æˆ–å…¶å®ƒ
   é¢†åŸŸä¸­æœªè§è¿‡çš„ items æ—¶ï¼Œè·å¾—äº†<strong><mark>è‰¯å¥½çš„ zero-shot æ€§èƒ½</mark></strong>ã€‚

<p align="center"><img src="/assets/img/p5-paper/fig-1.png" width="100%" height="100%"></p>
<p align="center">
Figure 1: P5 pretrains on an encoderâ€“decoder Transformer model that takes in textual inputs and produces target responses.
We trained P5 on a multitask collection of personalized prompts. After multitask prompt-based pretraining on recommendation datasets, P5 achieves the capability of zero-shot generalization to unseen personalized prompts and new items.
</p>

# 2 ç›¸å…³å·¥ä½œ

## 2.1 ç»Ÿä¸€æ¡†æ¶çš„å°è¯•

ä¹‹å‰å·²ç»æœ‰ä¸€äº›å·¥ä½œè¯•å›¾<strong><mark>åœ¨ç»Ÿä¸€æ¨¡å‹ä¸­è§£å†³å„ç§æ¨èä»»åŠ¡</mark></strong>ã€‚

### åŸºäºé€šç”¨è¯­è¨€æ¨¡å‹ï¼ˆT5 å’Œ GPT3ï¼‰

æ—©æœŸå…ˆé©±ï¼Œ

* <strong><mark><code>T5</code></mark></strong> ï¼šé€šè¿‡ <strong><mark><code>text-to-text encoder-decoder</code></mark></strong> æ¡†æ¶ç»Ÿä¸€äº† NLP ä¸‹æ¸¸ä»»åŠ¡ã€‚
* <strong><mark><code>GPT-3</code></mark></strong>ï¼šé€šè¿‡ <strong><mark><code>autoregressive language modeling</code></mark></strong> ç»Ÿä¸€äº† NLP ä¸‹æ¸¸ä»»åŠ¡ã€‚

å®ƒä»¬éƒ½èƒ½åŸºäºåŒä¸€ä¸ªé¢„è®­ç»ƒçš„<strong><mark>è¯­è¨€æ¨¡å‹</mark></strong>å®ç°ä¸åŒä»»åŠ¡ä¹‹é—´çš„æœ‰æ•ˆ<strong><mark>çŸ¥è¯†å…±äº«</mark></strong>ï¼ˆå³ï¼Œ<strong><mark>é€šç”¨æ¨¡å‹</mark></strong>ï¼‰ã€‚

### åŸºäºè‡ªç„¶è¯­è¨€çš„ seq-to-seq æ¶æ„

æœ€è¿‘ä¸šç•Œå¼€å§‹ä¸“æ³¨äºé€šè¿‡ä¸€ä¸ªå…±äº«çš„ <strong><mark><code>sequence-to-sequence</code></mark></strong>
æ¡†æ¶ç»Ÿä¸€<strong><mark>å¤§è§„æ¨¡è¯­è¨€ä»»åŠ¡</mark></strong> [1, 51, 67] æˆ–<strong><mark>è·¨æ¨¡æ€åº”ç”¨</mark></strong> [6, 66, 71]ï¼Œ
å…¶ä¸­ä¸åŒç±»å‹çš„ä»»åŠ¡å’Œæ¨¡æ€<strong><mark>éƒ½ä»¥è‡ªç„¶è¯­è¨€å½¢å¼è¡¨è¾¾</mark></strong>ã€‚

ä½†æ˜¯ï¼Œè¿™ç±»æ–¹æ³•æ²¡æœ‰åœ¨æ¨¡å‹ä¸­è€ƒè™‘<strong><mark>ä¸ªæ€§åŒ–</mark></strong>ã€‚

### åŸºäºé€šç”¨ç”¨æˆ·è¡¨ç¤º

[56, 57, 72] å°è¯•å­¦ä¹ æ˜“äºè¿ç§»åˆ°ä¸‹æ¸¸ä»»åŠ¡çš„<strong><mark>é€šç”¨ç”¨æˆ·è¡¨ç¤º</mark></strong>ã€‚
è¿™äº›æ–¹æ³•çš„ä¸€ä¸ªå±€é™æ€§æ˜¯å®ƒä»¬<strong><mark>ä»ç„¶éœ€è¦åœ¨ä¸‹æ¸¸æ•°æ®é›†ä¸Šè¿›è¡Œ finetuning</mark></strong>ã€‚

ç›¸æ¯”ä¹‹ä¸‹ï¼ŒP5 å°†ä¸ªæ€§åŒ–çº³å…¥ encoder-decoder Transformer æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥æ³›åŒ–åˆ°å¹¿æ³›çš„éœ€è¦ä¸ªæ€§åŒ–æ¨èçš„åœºæ™¯ã€‚
æ­¤å¤–ï¼Œå€ŸåŠ© prompt-based pretrainingï¼ŒP5 åœ¨è¿ç§»åˆ°æœªè§è¿‡çš„ prompts å’Œ items æ—¶è·å¾—äº†è‰¯å¥½çš„ zero-shot generalization èƒ½åŠ›ã€‚

## 2.2 é€šè¿‡æç¤ºçš„æ–¹å¼å­¦ä¹ ï¼ˆPrompt Learningï¼‰

GPT ç³»åˆ—å°¤å…¶æ˜¯ GPT-3 çš„æˆåŠŸæ ‡å¿—ç€ <strong><mark>prompt åœ¨ NLP ä»»åŠ¡ä¸­çš„æ™®åŠ</mark></strong>ã€‚

* åœ¨äº’è”ç½‘ä¸Šæ”¶é›†çš„å¤§é‡è¯­è¨€æ•°æ®è¿›è¡Œè®­ç»ƒï¼ŒGPT-3 å±•ç¤ºäº†åœ¨æä¾›å°‘é‡è¾“å…¥-è¾“å‡ºç¤ºä¾‹ä½œä¸º exemplar prompts æ—¶è§£å†³ NLP ä»»åŠ¡çš„èƒ½åŠ›ã€‚
* å…¶ä»–ä¸€äº›éµå¾ª â€œpretrain, prompt, and predictâ€ èŒƒå¼çš„ prompt è®¾è®¡æ–¹æ³•æœ€è¿‘ä¹Ÿæœ‰å‘å±• [37]ã€‚
    * [16, 23, 36, 40, 58] æ¢ç´¢äº†é’ˆå¯¹<strong><mark>ç‰¹å®šç¦»æ•£æç¤º</mark></strong>çš„æœç´¢ã€‚
    * [18, 28, 33, 38, 45, 81] åˆ©ç”¨<strong><mark>è¿ç»­å‘é‡ embedding </mark></strong>ä½œä¸ºæç¤ºã€‚

ç”±äº instruction-based prompt åŒ…å«è¯¦ç»†çš„ä»»åŠ¡æè¿°ï¼Œæ›´ç¬¦åˆè‡ªç„¶è¯­è¨€æ–¹å¼ï¼Œè€Œä¸”
ä¸äººç±»çš„äº¤æµæ–¹å¼å¾ˆç±»ä¼¼ï¼Œä¸€äº›å·¥ä½œ [11, 68] è®¤ä¸ºä»å¤šæ ·çš„ NLP æ•°æ®é›†å­¦ä¹ æ˜¯é€šå¾€é€šç”¨ NLP ç³»ç»Ÿçš„ä¸€ç§æ–¹å¼ã€‚
æœ€è¿‘çš„å·¥ä½œå¦‚ FLAN [67] å’Œ T0 [51] åœ¨å¤§å‹ NLP æ•°æ®é›†ä¸Šå¾®è°ƒ pretrained language modelsï¼Œè¿™äº›æ•°æ®é›†é€šè¿‡äººç±»å¯è¯»çš„æç¤ºè¿›è¡Œç»„ç»‡ï¼Œ
åœ¨æœªè§è¿‡çš„ä»»åŠ¡ä¸Šè¡¨ç°å‡ºå¼ºå¤§ zero-shot èƒ½åŠ›ã€‚

å—è¿™äº›æ–¹æ³•æˆåŠŸçš„å¯å‘ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ª<strong><mark>ä¸ªæ€§åŒ–æç¤ºé›†</mark></strong>ï¼Œ
ç„¶ååœ¨ä¸€ä¸ª<strong><mark>å¤šæ ·åŒ–çš„æ¨èä»»åŠ¡</mark></strong>ä¸Šè®­ç»ƒä¸€ä¸ª
<strong><mark>sequence-to-sequence æ¨¡å‹</mark></strong>ã€‚

## 2.3 æ¨èé¢†åŸŸçš„ NLP

æ¨èå·²ç»ä¸ NLP æŠ€æœ¯æœ‰å¾ˆé•¿æ—¶é—´çš„äº¤é›†äº†ã€‚å››ä¸ªä¸»è¦æ–¹å‘ï¼š

1. <strong><mark><code>explainable recommendation</code></mark></strong> [4, 10, 30â€“32, 75, 77] where NLP models help generating text explanations for a given recommendation;
2. <strong><mark><code>sequential recommendation</code></mark></strong> as language modeling [9, 60, 80] which considers user interaction histories as word token sequences;
3. <strong><mark><code>text feature extraction</code></mark></strong> [69, 74, 79] which aims to extract informative text encodings that can improve the performance of recommendation;
4. <strong><mark><code>conversational recommendation</code></mark></strong> [8, 12â€“14, 22, 61, 76] that reasons the intent of users and gives recommendation in an interactive dialog format.

æœ¬æ–‡ä¸»è¦æ¶µç›–å‰ä¸¤ç§ä»»åŠ¡ï¼Œ
å¹¶è®¨è®ºäº†å¦‚ä½•è®¾è®¡ä¸€ä¸ªç»Ÿä¸€çš„ NLP æ¡†æ¶æ¥æ¶µç›– rating predictionã€top-k recommendation å’Œ review summarization ç­‰ä»»åŠ¡ã€‚

æ­¤å¤–ï¼Œé€šè¿‡ä½¿ç”¨ä¸ä¼ ç»Ÿç›¸ä¼¼çš„æŒ‡ä»¤å¼æç¤ºè¿›è¡Œé¢„è®­ç»ƒï¼ŒP5 å—ç›Šäºè‡ªç„¶è¯­è¨€ç¯å¢ƒï¼Œæé«˜äº†åœ¨ç³»åˆ—æ¨èä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚

## 2.4 Zero-shot å’Œå†·å¯åŠ¨æ¨è

æ¨èç³»ç»Ÿçš„æ€§èƒ½<strong><mark>å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºå¯ç”¨çš„è®­ç»ƒæ•°æ®</mark></strong>ï¼Œä½†æ€»æ˜¯å­˜åœ¨é›¶æ ·æœ¬æˆ–å°‘æ ·æœ¬çš„æƒ…å†µã€‚
å¦‚æœåœ¨è¿™ç±»å†·å¯åŠ¨åœºæ™¯ä¸‹ï¼Œæ¨èç³»ç»Ÿçš„è¡¨ç°ä¹Ÿå¾ˆå¥½ï¼Œå°±è¡¨æ˜è¿™ä¸ªæ¨èæ¨¡å‹å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

ä¸€ä¸ªå¸¸è§çš„ç ”ç©¶æ˜¯å†·å¯åŠ¨æ¨èï¼Œå³ç”¨æˆ· [26] æˆ–ç‰©å“ [53] æ˜¯æ–°ç³»ç»Ÿï¼Œæ²¡æœ‰ä¹‹å‰çš„äº¤äº’è®°å½•ã€‚

* å¸¸è§è§£å†³æ–¹æ¡ˆæ˜¯å­¦ä¹ å»å»ºæ¨¡å†…å®¹ç‰¹å¾ [15, 29, 44, 55]ï¼Œä»¥ä¾¿åœ¨æ²¡æœ‰äº¤äº’è®°å½•çš„æƒ…å†µä¸‹è¿›è¡Œæ¨ç†ï¼Œæˆ–è€…æ˜¯ä»å…¶ä»–çš„è¾…åŠ©åŸŸå­¦ä¹ è¿ç§»è¡¨ç¤º [42, 56, 59, 72, 82]ã€‚
* å¦ä¸€ç§è§£å†³æ–¹å¼æ˜¯å¿«é€Ÿé€‚åº”æ–°åŸŸï¼ˆquick adaptation to the new domainï¼‰ï¼Œè€Œéä¾›å†·å¯åŠ¨ caseã€‚
  è§£å†³æ–¹æ¡ˆé€šå¸¸éµå¾ª<strong><mark>meta learning</mark></strong> [27, 64] æˆ–<strong><mark>å› æœå­¦ä¹ </mark></strong> [34] (causal learning) æ¡†æ¶ï¼Œä½¿æ¨¡å‹å¯¹åŸŸé€‚åº”å…·æœ‰é²æ£’æ€§ã€‚

åœ¨æˆ‘ä»¬çš„å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è¦æ±‚ P5 æ¨¡å‹åœ¨è¾…åŠ©åŸŸä¸Šé¢„è®­ç»ƒï¼Œä»¥è§£å†³ç›®æ ‡åŸŸä¸Šçš„ä»»åŠ¡ï¼Œå…¶ä¸­ç”¨æˆ·å¯¹ P5 æ˜¯å·²çŸ¥çš„ï¼Œä½†ç‰©å“ P5 æ˜¯æ²¡è§è¿‡çš„ã€‚

# 3 ä¸ªæ€§åŒ– prompts é›†åˆ

ä¸ºäº†æ–¹ä¾¿ multitask prompt-based pretrainingï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªä¸ªæ€§åŒ–æç¤ºé›†ã€‚
ä¸ªæ€§åŒ–æç¤ºé›†è¦†ç›–äº†äº”ç±»ä¸åŒçš„ä»»åŠ¡ï¼š

1. rating prediction
2. sequential recommendation
3. explanation
4. review
5. direct recommendation

æ¯ç±»ä»»åŠ¡åŒ…å«å¤šä¸ªä¸ªæ€§åŒ–æç¤ºï¼Œå¸®åŠ© P5 å‘ç°ç”¨æˆ·å’Œç‰©å“çš„å„ä¸ªæ–¹é¢å…³è”ã€‚

[51] ä¸­ï¼Œä¸€ä¸ªæç¤ºç”±ä¸€ä¸ªè¾“å…¥æ¨¡æ¿å’Œä¸€ä¸ªç›®æ ‡æ¨¡æ¿ç»„æˆï¼Œä»¥åŠä¸€ç»„ç›¸å…³çš„å…ƒæ•°æ®ã€‚
åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å®šä¹‰ä¸ªæ€§åŒ–æç¤ºä¸ºåŒ…å«ä¸ªæ€§åŒ–å­—æ®µçš„æç¤ºï¼Œç”¨äºä¸åŒçš„ç”¨æˆ·å’Œç‰©å“
ï¼ˆa prompt that includes <strong><mark><code>personalized fields for different users and items</code></mark></strong>ï¼‰ã€‚

ä¾‹å¦‚ï¼Œä¸€ä¸ªç”¨æˆ·çš„åå¥½å¯ä»¥é€šè¿‡ä¸€ä¸ª ID æè¿°ï¼Œä¹Ÿå¯ä»¥é€šè¿‡ä¸€æ®µæ–‡æœ¬æè¿°è¡¨ç¤ºã€‚
æ­¤å¤–ï¼Œç»™å®šä¸ªæ€§åŒ–æç¤ºï¼ŒæœŸæœ›æ¨¡å‹è¾“å‡ºä¹Ÿåº”è¯¥æ ¹æ®å…¶ç‰©å“å­—æ®µè€Œå˜åŒ–ã€‚è¿™æŒ‰æ—¶çš„è¯´ç”¨æˆ·å¯¹ä¸åŒç‰©å“çš„ä¸åŒåå¥½ã€‚
è¿™æ ·çš„ç‰©å“å­—æ®µå¯ä»¥è¡¨ç¤ºä¸ºç‰©å“ ID å·ç æˆ–åŒ…å«è¯¦ç»†æè¿°çš„ç‰©å“å…ƒæ•°æ®ã€‚

## 3.1 Prompts è®¾è®¡

æˆ‘ä»¬é’ˆå¯¹æ¯ä¸ªä»»åŠ¡è®¾è®¡äº†ä¸€ä¸ªåŸºæœ¬çš„ä¸ªæ€§åŒ–æç¤ºé›†ã€‚

### rating prediction æç¤ºè¯è®¾è®¡

å¯¹äº rating prediction ä»»åŠ¡ï¼Œæˆ‘ä»¬å°†å…¶æç¤ºåˆ†ä¸ºä¸‰ä¸ªç±»åˆ«ï¼š

1. ç»™å®šç”¨æˆ·å’Œç‰©å“çš„ä¿¡æ¯ï¼Œç›´æ¥é¢„æµ‹<strong><mark>ç”¨æˆ·ç»™è¯¥ç‰©å“çš„è¯„åˆ†</mark></strong>ï¼ŒèŒƒå›´ä» 1 åˆ° 5ï¼›
2. é¢„æµ‹<strong><mark>ç”¨æˆ·æ˜¯å¦ä¼šç»™ä¸€ä¸ªç‰©å“æŒ‡å®šçš„è¯„åˆ†</mark></strong>ï¼ˆrate an item a given scoreï¼‰ã€‚æœŸæœ›è¾“å‡ºæ˜¯ yes æˆ– noï¼›
3. é¢„æµ‹<strong><mark>ç”¨æˆ·æ˜¯å¦å–œæ¬¢æˆ–ä¸å–œæ¬¢ä¸€ä¸ªç‰©å“</mark></strong>ã€‚

æˆ‘ä»¬è€ƒè™‘è¯„åˆ†ç­‰äºæˆ–å¤§äº 4 ä¸ºç”¨æˆ·çš„å–œæ¬¢åå¥½ï¼Œè€Œè¾ƒä½çš„è¯„åˆ†è¡¨ç¤ºç”¨æˆ·çš„ä¸å–œæ¬¢åå¥½ã€‚

### <strong><mark><code>sequential recommendation</code></mark></strong> æç¤ºè¯è®¾è®¡

é’ˆå¯¹ sequential recommendation ä»»åŠ¡ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸‰ç§ç±»å‹çš„æç¤ºï¼š

1. åŸºäºç”¨æˆ·äº¤äº’å†å²ï¼Œç›´æ¥<strong><mark>é¢„æµ‹ä¸‹ä¸€ä¸ªç‰©å“</mark></strong>ï¼›
2. ç»™å®šç”¨æˆ·äº¤äº’å†å²ï¼Œ<strong><mark>ä»å€™é€‰åˆ—è¡¨ä¸­é€‰æ‹©å¯èƒ½çš„ä¸‹ä¸€ä¸ªç‰©å“</mark></strong>ï¼Œå…¶ä¸­åªæœ‰ä¸€ä¸ªç‰©å“æ˜¯æ­£æ ·æœ¬ï¼›
3. åŸºäºç”¨æˆ·äº¤äº’å†å²ï¼Œ<strong><mark>é¢„æµ‹ç»™å®šç‰©å“æ˜¯å¦ä¼šè¢«ç”¨æˆ·ä¸‹æ¬¡äº¤äº’</mark></strong>ã€‚

### <strong><mark><code>explanation</code></mark></strong> æç¤ºè¯è®¾è®¡

é’ˆå¯¹ explanation ä»»åŠ¡ï¼Œæˆ‘ä»¬è¦æ±‚ P5 <strong><mark>ç”Ÿæˆä¸€ä¸ªæ–‡æœ¬è§£é‡Šï¼Œä»¥è¯æ˜ç”¨æˆ·å¯¹ç»™å®šç‰©å“çš„åå¥½</mark></strong>ã€‚ä¸¤ç§æç¤ºï¼š

1. ç›´æ¥<strong><mark>ç”Ÿæˆä¸€ä¸ªåŒ…å«ç”¨æˆ·å’Œç‰©å“ä¿¡æ¯çš„è§£é‡Šå¥å­</mark></strong>ï¼›
2. <strong><mark>åŸºäºä¸€ä¸ªç‰¹å¾è¯ä½œä¸ºæç¤ºï¼Œç”Ÿæˆè§£é‡Š</mark></strong>ã€‚

å¯¹äºæ¯ä¸ªç±»åˆ«ï¼Œå¯èƒ½è¿˜åŒ…æ‹¬å…¶ä»–è¾…åŠ©ä¿¡æ¯ï¼Œä¾‹å¦‚è¯„è®ºæ ‡é¢˜å’Œè¯„åˆ†ã€‚

### review ç›¸å…³æç¤ºè¯è®¾è®¡

é’ˆå¯¹ review ç›¸å…³ä»»åŠ¡ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸¤ç§ç±»å‹çš„æç¤ºï¼š

1. æ€»ç»“è¯„è®ºï¼Œ<strong><mark>ç”Ÿæˆä¸€ä¸ªæ›´çŸ­çš„è¯„è®ºæ ‡é¢˜</mark></strong>ï¼›
2. <strong><mark>åŸºäºç»™å®šçš„è¯„è®ºï¼Œé¢„æµ‹ç›¸åº”çš„è¯„åˆ†</mark></strong>ã€‚

### <strong><mark><code>direct recommendation</code></mark></strong> æç¤ºè¯è®¾è®¡

é’ˆå¯¹ direct recommendation ä»»åŠ¡ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸¤ç§ç±»å‹çš„æç¤ºï¼š

1. é¢„æµ‹<strong><mark>æ˜¯å¦å‘ç”¨æˆ·æ¨èä¸€ä¸ªç‰©å“</mark></strong>ï¼ŒæœŸæœ›è¾“å‡ºæ˜¯ yes æˆ– noï¼›
2. <strong><mark>ä»å€™é€‰ç‰©å“åˆ—è¡¨ä¸­é€‰æ‹©æœ€åˆé€‚çš„ç‰©å“æ¨èç»™ç”¨æˆ·</mark></strong>ã€‚

å®Œæ•´çš„ä¸ªæ€§åŒ–æç¤ºé›†è§é™„å½•ã€‚

## 3.2 ä»åŸå§‹æ•°æ®æ„å»ºè®­ç»ƒæ•°æ®é›†ï¼ˆprompts & answersï¼‰

æ„å»ºè®­ç»ƒæ•°æ®çš„è¿‡ç¨‹å¦‚å›¾ 2 æ‰€ç¤ºï¼Œ

<p align="center"><img src="/assets/img/p5-paper/fig-2.png" width="100%" height="100%"></p>
<p align="center">
å›¾ 2ï¼šæ ¹æ®è®¾è®¡çš„ä¸ªæ€§åŒ–æç¤ºæ¨¡æ¿ï¼Œä»åŸå§‹æ•°æ®æ„å»ºè®­ç»ƒç”¨çš„ input-target pairs æˆ–é›¶æ ·æœ¬æµ‹è¯•ä¸ªæ€§åŒ–æç¤ºã€‚
åŸå§‹æ•°æ®æ¥è‡ªä¸‰ä¸ªæ•°æ®æºã€‚
å…·ä½“çš„ï¼Œrating/review/explanation ï¼ˆaï¼‰å…±äº«ç›¸åŒçš„åŸå§‹æ•°æ®ï¼Œè€Œ sequential recommendation (b) å’Œ direct recommendation (c) ä½¿ç”¨ç±»ä¼¼çš„åŸå§‹æ•°æ®ï¼Œä½†å‰è€…è¿˜éœ€è¦ç”¨æˆ·äº¤äº’å†å²ã€‚
å®Œæ•´çš„ P5 ä¸ªæ€§åŒ–æç¤ºé›†è§é™„å½•ã€‚
</p>

è®­ç»ƒæ•°æ®å’Œé¢„è®­ç»ƒä»»åŠ¡å¯¹è¿™äº›æ•°æ®ä¸­çš„ä¿¡æ¯è¿›è¡Œèƒå–ï¼Œæç‚¼ç”¨æˆ·çš„<strong><mark>åå¥½å’Œä¸ªæ€§åŒ–</mark></strong>ä¿¡æ¯ã€‚
é¢„è®­ç»ƒæ—¶ï¼Œæˆ‘ä»¬å°†ä¸åŒä»»åŠ¡çš„ input-target pairs æ··åˆåœ¨ä¸€èµ·ä½œä¸ºè®­ç»ƒæ•°æ®ã€‚

ä¸ºäº†å¢å¼º P5 çš„é²æ£’æ€§å’Œé›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼Œå¯¹äºæ¯ä¸ªåŸå§‹æ•°æ®ï¼Œæˆ‘ä»¬åªé‡‡æ ·ä¸€éƒ¨åˆ†ï¼Œè€Œä¸æ˜¯æ¯ä¸ªä»»åŠ¡ä¸­çš„æ‰€æœ‰ä¸ªæ€§åŒ–æç¤ºã€‚
åœ¨ sequential å’Œ direct recommendation ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬è¿˜ä¼šå¯¹é‚£äº›éœ€è¦å€™é€‰åˆ—è¡¨çš„åœºæ™¯éšæœºé€‰æ‹©ä¸€äº›è´Ÿç‰©å“ã€‚

# 4 P5 èŒƒå¼ä¸æ¨¡å‹

æ‰€æœ‰é¢„è®­ç»ƒæ•°æ®å…±äº«ç»Ÿä¸€çš„ input-target token åºåˆ—æ ¼å¼ï¼Œæ‰“ç ´äº†ä¸åŒä»»åŠ¡ä¹‹é—´çš„ç•Œé™ã€‚
åœ¨æ¡ä»¶ç”Ÿæˆç»Ÿä¸€æ¡†æ¶ä¸‹<strong><mark>é¢„è®­ç»ƒå¤šä¸ªæ¨èä»»åŠ¡</mark></strong>å¯ä»¥æå‡æ‰€æœ‰ä»»åŠ¡çš„æ•ˆæœã€‚

æ•´ä¸ªé¢„è®­ç»ƒé˜¶æ®µå°† P5 æ²‰æµ¸åœ¨å®Œæ•´çš„è¯­è¨€ç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬æœŸæœ›å¢å¼ºå…¶é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿç†è§£æ–°é¢–çš„ä¸ªæ€§åŒ–æç¤ºï¼Œå³ä½¿è¿™äº›æç¤ºåŒ…å«è¯¦ç»†çš„ç‰©å“æè¿°ã€‚
è¿™å°±æ˜¯ä¸ºä»€ä¹ˆ P5 è¢«ç§°ä¸ºç»Ÿä¸€çš„â€œé¢„è®­ç»ƒã€ä¸ªæ€§åŒ–æç¤ºå’Œé¢„æµ‹èŒƒå¼â€ï¼ˆ"Pretrain, Personalized Prompt, and Predict Paradigm"ï¼‰ã€‚

## 4.1 P5 æ¶æ„

å…·ä½“åˆ° P5 æ¶æ„ï¼Œæˆ‘ä»¬é‡‡ç”¨åŸºæœ¬çš„ encoder-decoder æ¡†æ¶ï¼Œå¹¶ä½¿ç”¨ Transformer æ„å»ºç¼–ç å™¨å’Œè§£ç å™¨ã€‚

å‡è®¾è¾“å…¥ token åºåˆ—çš„ embedding ä¸º $\mathbf{x} = \left[x_1, \cdots, x_n\right]$ã€‚å¦‚ Figure 3 æ‰€ç¤ºï¼Œ

<p align="center"><img src="/assets/img/p5-paper/fig-3.png" width="100%" height="100%"></p>
<p align="center">
å›¾ 3ï¼šP5 æ¶æ„ç¤ºæ„å›¾ã€‚å¯¹äºç¤ºä¾‹ prompt è¾“å…¥ <strong><mark><code>What star rating do you think user_23 will
give item_7391?</code></mark></strong>ï¼ŒP5 é¦–å…ˆä½¿ç”¨åŒå‘æ–‡æœ¬ç¼–ç å™¨ç¼–ç è¾“å…¥ï¼Œç„¶åé€šè¿‡æ–‡æœ¬è§£ç å™¨è‡ªå›å½’åœ°ç”Ÿæˆç­”æ¡ˆã€‚
ä¸ä»»åŠ¡ç‰¹å®šçš„æ¨èæ¨¡å‹ä¸åŒï¼ŒP5 åŸºäº multitask prompt-based pretrainingï¼Œå› æ­¤èƒ½å¤Ÿé€‚åº”ä¸åŒçš„ä»»åŠ¡ï¼Œæ³›åŒ–èƒ½åŠ›å¾ˆå¼ºã€‚
</p>

### ä½ç½®ç¼–ç 

å¢åŠ ä½ç½®ç¼–ç ï¼Œä»¥æ•è·åºåˆ—ä¸­çš„ä½ç½®ä¿¡æ¯ã€‚

### Whole-word embeddingï¼Œè¡¥å¿ item token è¡¨ç¤ºè¢« tokenizer æ‹†åˆ†å¸¦æ¥çš„è¯­ä¹‰æŸå¤±

ä¸ºäº†ä½¿ P5 æ•æ‰è¾“å…¥åºåˆ—ä¸­åŒ…å«çš„ä¸ªæ€§åŒ–ä¿¡æ¯ï¼Œæˆ‘ä»¬è¿˜åº”ç”¨ whole-word embedding  $\mathcal{W}$ æ¥è¡¨ç¤º<strong><mark>è¿ç»­çš„ sub-word token æ˜¯å¦æ¥è‡ªåŒä¸€ä¸ªåŸå§‹å•è¯</mark></strong>ã€‚

ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªæ­¥éª¤å‘¢ï¼Ÿä¸¾ä¸ªä¾‹å­ï¼Œ

* å¦‚æœæˆ‘ä»¬ç›´æ¥ç”¨ ID 7391 è¡¨ç¤ºç‰©å“ï¼Œå³ <strong><mark><code>item_7391</code></mark></strong>ï¼Œ
  é‚£ä¹ˆè¿™ä¸ªè¯ç»è¿‡ SentencePiece tokenizer ä¹‹åï¼Œå°±ä¼šå˜æˆ 4 ä¸ªç‹¬ç«‹çš„ tokenï¼ˆ<strong><mark><code>item, _, 73, 91</code></mark></strong>ï¼‰ï¼Œè€Œä¸æ˜¯æˆ‘ä»¬æœŸæœ›çš„ä¸€ä¸ªã€‚
  é€šè¿‡å…±äº«çš„ whole-word embedding ï¼ˆå›¾ 3 ä¸­çš„ `<w10>`ï¼‰ï¼ŒP5 å¯ä»¥æ›´å¥½åœ°è¯†åˆ«åŒ…å«ä¸ªæ€§åŒ–ä¿¡æ¯çš„å­—æ®µã€‚
* å¦ä¸€ç§æ–¹æ¡ˆæ˜¯æ¯ä¸ªç”¨æˆ·/ç‰©å“ç”¨ä¸€ä¸ªç‹¬ç«‹çš„é¢å¤– token è¡¨ç¤ºï¼ˆä¾‹å¦‚ï¼Œ`<item_7391>`ï¼‰ã€‚
  ç„¶è€Œï¼Œå½“ç”¨æˆ·å’Œç‰©å“æ•°é‡å¾ˆå¤§æ—¶ï¼Œè¿™å¯èƒ½ä¼šå¼•å…¥å¤§é‡çš„é¢å¤– tokenã€‚

### encoder & decoder

æ¥ä¸‹æ¥ï¼Œæ–‡æœ¬ç¼–ç å™¨å°†ä¸Šè¿°ä¸‰ä¸ª embedding çš„å’Œ $\mathbf{e} = \left[e_1, \cdots, e_n\right]$ ä½œä¸ºè¾“å…¥ï¼Œ
å¹¶è¾“å‡ºä¸Šä¸‹æ–‡åŒ–ä¹‹åçš„è¡¨ç¤º $\mathbf{t} = \left[t_1, \cdots, t_n\right] = \mathcal{E}(\mathbf{e})$ã€‚

è§£ç å™¨ $\mathcal{D}(\cdot)$ ç„¶åå…³æ³¨ä¹‹å‰ç”Ÿæˆçš„ token $\mathbf{y}$
å’Œç¼–ç å™¨è¾“å‡º $\mathbf{t}$ï¼Œå¹¶é¢„æµ‹æœªæ¥ token çš„æ¦‚ç‡åˆ†å¸ƒï¼š

$$P_{\theta}\left(\mathbf{y}_{j} \mid \mathbf{y}_{<j}, \mathbf{x}\right) = \mathcal{D}(\mathbf{y}_{<j}, \mathbf{t})$$ã€‚

åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼ŒP5  minimizing the negative
log-likelihood of label tokens y conditioned on input text x in an end-to-end mannerï¼š

<p align="center"><img src="/assets/img/p5-paper/eq-1.png" width="50%" height="50%"></p>

è¿™ä¸ªç›¸åŒçš„æŸå¤±å‡½æ•°è¢«æ‰€æœ‰ P5 ä¸‹çš„æ¨èä»»åŠ¡å…±äº«ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ç»Ÿä¸€æ¨èä»»åŠ¡ï¼Œä½¿ç”¨ä¸€ä¸ªæ¨¡å‹ã€ä¸€ä¸ªæŸå¤±å’Œä¸€ä¸ªæ•°æ®æ ¼å¼ã€‚

## 4.2 ç”¨é¢„è®­ç»ƒçš„ P5 è¿›è¡Œæ¨èä»»åŠ¡ï¼ˆæ¨ç†ï¼‰

åœ¨é¢„è®­ç»ƒä¹‹åï¼ŒP5 å¯ä»¥ç›´æ¥ä¸ªæ€§åŒ–æç¤ºæ‰§è¡Œä¸åŒçš„ä»»åŠ¡ï¼Œä¸ç®¡è¿™äº› prompts å®ƒæœ‰æ²¡æœ‰è§è¿‡ã€‚

* å¯¹äº ratingã€explanation å’Œ review ä»»åŠ¡ï¼Œç®€å•åœ°ä½¿ç”¨<strong><mark>è´ªå¿ƒè§£ç </mark></strong>ï¼ˆgreedy decodingï¼‰æ¥ç”Ÿæˆç­”æ¡ˆã€‚
* å¯¹äº sequential å’Œ direct recommendation ä»»åŠ¡ï¼Œé€šå¸¸éœ€è¦ä¸€ä¸ªç‰©å“åˆ—è¡¨ä½œä¸ºç›®æ ‡è¾“å‡ºï¼Œä½¿ç”¨ <strong><mark><code>beam search</code></mark></strong>ã€‚

å¯¹äº sequential recommendationï¼Œæˆ‘ä»¬åº”ç”¨ beam search ç”Ÿæˆä¸€ä¸ªæ½œåœ¨çš„ä¸‹ä¸€ä¸ªç‰©å“åˆ—è¡¨ã€‚
å¯¹äº direct recommendationï¼Œæˆ‘ä»¬ä»ä¸€ä¸ªå€™é€‰ç‰©å“é›†åˆ $\mathbf{S} = \{S_1, \cdots, S_m\}$ ä¸­é¢„æµ‹æ¨èçš„ç‰©å“ï¼Œå…¶ä¸­åªæœ‰ $m$ ä¸ªå€™é€‰ç‰©å“ä¸­çš„ä¸€ä¸ªæ˜¯æ­£æ ·æœ¬ã€‚
è¿™é‡Œï¼Œæˆ‘ä»¬åŒæ ·ä½¿ç”¨ beam search è§£ç ä¸€ä¸ªå…·æœ‰æœ€é«˜åˆ†æ•°çš„æ½œåœ¨ç›®æ ‡ç‰©å“åˆ—è¡¨ï¼Œç„¶åè¿›è¡Œè¯„ä¼°ã€‚
ä¸Šè¿°ä¸¤ç§è§£ç è¿‡ç¨‹å¯ä»¥å†™ä¸ºï¼š

<p align="center"><img src="/assets/img/p5-paper/eq-2.png" width="50%" height="50%"></p>

å…¶ä¸­ $B$ è¡¨ç¤º beam sizeï¼Œ$\mathbf{C}$ è¡¨ç¤ºè¾“å‡ºç‰©å“åˆ—è¡¨ã€‚

# 5 å®éªŒ

æœ¬èŠ‚æˆ‘ä»¬è¯„ä¼° P5 åœ¨çœŸå®ä¸–ç•Œæ•°æ®ä¸Šçš„æ€§èƒ½ï¼Œå¹¶ä¸å…¶ä»–ä»£è¡¨æ€§æ–¹æ³•è¿›è¡Œæ¯”è¾ƒã€‚
é€šè¿‡æ€§èƒ½æ¯”è¾ƒå’Œæ¶ˆèç ”ç©¶ï¼Œæˆ‘ä»¬æ—¨åœ¨å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š

## 5.0 è¦å›ç­”çš„é—®é¢˜ (RQ 1~5)

### é—®é¢˜ä¸€ï¼šP5 ä¸ task-specific æ–¹æ³•çš„æ€§èƒ½æ¯”è¾ƒ
How does our unified P5 framework perform compared with task-specific methods on all five task families?

### é—®é¢˜äºŒï¼šP5 çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›
Does P5 have enough zero-shot generalization ability when transferring to unseen personalized prompts for either existing or new items?

### é—®é¢˜ä¸‰ï¼šP5 çš„æ€§èƒ½å¦‚ä½•å—æ¨¡å‹å¤§å°ã€ä»»åŠ¡æ•°é‡å’Œæç¤ºæ•°é‡å½±å“ï¼Ÿ

How do scaling factors such as model size, number of task
families, and number of prompts affect the performance of P5?

### é—®é¢˜å››ï¼šP5 ä¸­å®ç°ä¸ªæ€§åŒ–æ¨èçš„æœ€ä½³æ–¹å¼æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆ<strong><mark><code>unique token vs. sub-word units</code></mark></strong>ï¼‰

Which is a better way to implement personalization in P5:
adopting an independent extra token for each user or item (e.g.,
â€œâŸ¨user_23âŸ©â€) or the default setting, i.e., tokenizing each user or
item into multiple sub-word units (e.g., â€œuserâ€, â€œ_â€, â€œ23â€)?

### é—®é¢˜äº”ï¼šP5 çš„é¢„è®­ç»ƒæ—¶é—´ï¼ŸP5 çš„æ¨ç†æ€§èƒ½ï¼Ÿ

How long does it take for P5 to conduct pretraining? Is it
efficient to make inference with the pretrained P5 model? We
provide statistics on training and inference time in the Appendix

## 5.1 Experimental Setup

### Datasets

We conduct extensive experiments over four real-world
datasets. The Amazon1 datasets are collected from Amazon.com
platform with user ratings and reviews on 29 categories of products. In this paper, we adopt three of them to evaluate our method,
namely Sports & Outdoors, Beauty, as well as Toys & Games. Besides,
Yelp2 dataset contains a large number of user ratings and reviews
for business recommendation. We follow [80] and use transaction
records between January 1, 2019 to December 31, 2019. Due to space
limit and that the results on Yelp show similar trends with other
datasets, we put the experimental results on Yelp dataset in the
Appendix. The detailed statistics of these datasets are presented in
Table 1.

<p align="center"> <img src="/assets/img/p5-paper/table-1.png" width="100%" height="100%"></p>

### Task splits

For rating, explanation, and review task families, we
randomly split each dataset into training (80%), validation (10%)
and testing (10%) sets, and ensure that there is at least one instance
included in the training set for each user and item. To obtain the
ground-truth explanations, following the natural language explanation works [30, 31], we first extract item feature words from
the reviews with the help of the Sentires toolkit3[77, 78], and then
extract the sentences from reviews that comment on one or more
item feature words as usersâ€™ explanation about their preference.
In terms of sequential recommendation task family, for each user
interaction sequence, the last item is used as the test data, the item
before the last one is used as the validation data, and the remaining
data is used for training. To avoid data leakage during pretraining,
we follow the training split of sequential recommendation to build
the training set for direct recommendation task family.

### Implementation Details

Our P5 model utilizes the pretrained
T5 checkpoints [47] as backbone. According to the size of T5 backbone, we create two versions of P5, namely P5-small (P5-S) and
P5-base (P5-B). For P5-small, there are 6 layers for both encoder
and decoder, the model dimensionality is 512 with 8-headed attention, and the number of parameters is 60.75 million. For P5-base,
encoder and decoder both have 12 Transformer blocks. The model
has an embedding dimensionality of 768 and a 12-headed attention,
and the number of parameters is 223.28 million. For tokenization,
we use the SentencePiece [54] tokenizer with a vocabulary size of
32,128 for parsing sub-word units. We pretrain P5 for 10 epochs
with AdamW optimization [39] on four NVIDIA RTX A5000 GPUs.
The batch size is set to 16 for P5-base and 32 for P5-small. We choose
1 Ã— 10âˆ’3 as the peak learning rate and set the maximum length
of input tokens to 512. The warmup strategy is used to adjust the
learning rate during training, the warmup stage is set to be the first
5% of all iterations. When negative sampling is needed for training,
we use 1:1 positive vs. negative sampling for both P5 and baselines.
Our default pretrainâ€“predict combination adopts the last prompt
in each task family for zero-shot evaluation while all remaining
prompts are utilized for multitask prompted pretraining. For rating prediction, we use Gaussian sampling to convert the original
integer scores to float numbers rounded to 1 decimal place. In this
way, we can avoid overfitting the limited score types. After this
change, we increase the number of score classes from 5 to 41. For
sequential recommendation, we set the beam size ğµ to 20. For direct
recommendation, the beam size is also 20 and the candidate pool
contains 100 items, which consist of one ground-truth item and 99
sampled negative ones that the user has not interacted with.

### è¯„ä¼°æŒ‡æ ‡ï¼ˆMetricsï¼‰

* å¯¹äº review predictionï¼Œæˆ‘ä»¬é‡‡ç”¨ Root Mean Square Error (RMSE) å’Œ Mean Absolute Error (MAE) è¯„ä¼°ã€‚
* å¯¹äº sequential recommendation å’Œ direct recommendationï¼Œæˆ‘ä»¬é‡‡ç”¨ <strong><mark><code>topK Hit Ratio</code></mark></strong> (HR@K)
  å’Œ <strong><mark><code>Normalized Discounted Cumulative Gain</code></mark></strong> (NDCG@K) è¯„ä¼°ï¼Œç»™å‡º `HR@1, 5, 10` å’Œ `NDCG@5, 10` çš„ç»“æœã€‚
* å¯¹äº explanation generation å’Œ review summarizationï¼Œæˆ‘ä»¬é‡‡ç”¨ BLEU-4, ROUGE-1, ROUGE-2, å’Œ ROUGE-L è¯„ä¼°ã€‚

RMSE å’Œ MAE æ˜¯â€œè¶Šä½è¶Šå¥½â€ï¼Œè€Œå…¶ä»–æŒ‡æ ‡æ˜¯â€œè¶Šé«˜è¶Šå¥½â€ã€‚å¯¹äºæ‰€æœ‰è¡¨æ ¼ï¼Œç²—ä½“æ•°å­—è¡¨ç¤ºæœ€ä½³æ€§èƒ½ï¼Œä¸‹åˆ’çº¿æ•°å­—è¡¨ç¤ºç¬¬äºŒæœ€ä½³æ€§èƒ½ã€‚

### Rating Prediction and Direct Recommendation

These tasks
take the userâ€“item rating/interaction data, but no content or side
information is provided. We aim to justify whether the models are
able to provide accurate rating prediction or recommendation lists
that align with the user preferences. We use MF [25] and MLP [5]
under mean square root loss as rating prediction baselines. For
direct recommendation, we use BPR-MF [49], BPR-MLP [5], and
a state-of-the-art contrastive learning-based collaborative filtering
model SimpleX [43] as baselines.

### Sequential Recommendation

We adopt several representative
sequential recommendation approaches as our baselines. Caser [63]
treats sequential recommendation as a Markov Chain and employs
convolutional neural networks to model user interests. HGN [41]
adopts a hierarchical gating networks to learn user behaviors from
the perspectives of both long and short terms. GRU4Rec [21] is
originally proposed for session-based recommendation. It utilizes
GRU [7] to model the user click history sequence. BERT4Rec [60]
mimics the BERT-style masked language modeling and learns a bidirectional representation for sequential recommendation. FDSA [73]
focuses on the feature transition patterns by modeling feature
sequence with a self-attention module. SASRec [24] adopts selfattention mechanism in a sequential recommendation model, which
reconciles the properties of Markov Chains and RNN-based approaches. S3-Rec [80] leverages self-supervised objectives to help
sequential recommendation model better discover the correlations
among different items and their attributes. We use the implementation of S3-Rec and its baselines for comparison4.

### Explanation Generation

For performance comparison, we consider several baselines with regard to the task of explanation generation. Attn2Seq [10] learns to encode attributes into vectors, and
then invokes an attention mechanism to generate reviews conditioned on the attribute vector. NRT [32] utilizes GRU [7] to generate
explanations based on user and item IDs. PETER [31] is a simple
and effective framework that attempts to utilize user and item IDs
to generate explanations. It is built upon a modified attention mask
of the Transformer architecture. There is also a variant PETER+,
which takes a hint feature word to assist the explanation generation.

### Review Related

For review summarization, we adopt pretrained
T0 [51] and GPT-2 [46] checkpoints hosted by Hugging Face5 as
baselines. For review preference prediction, we only use T0 to make
comparisons because GPT-2 cannot perform this task.

## 5.3 Performance Comparison on Different Task Families (RQ1)

In this section, we pretrain P5 with prompts from all five task
families to verify its multitask learning ability. According to the
default pretrainâ€“predict task combination, we leave Prompt 1-10,
Prompt 2-13, Prompt 3-12, Prompt 4-4, and Prompt 5-8 for zeroshot evaluation and pretrain P5 with the remaining personalized
prompts. The performances of P5 and relevant baselines on the
five task families are presented in Table 2 to Table 7. For each task
family, we choose one or more seen prompts as supplement to the
aforementioned zero-shot unseen prompts to perform evaluations.

### 5.3.1 Rating Prediction

Prompt 1-6 and Prompt 1-10 are used
for evaluating P5â€™s performance on rating prediction. The performance comparison is presented in Table 2. We can see that when
testing with seen Prompt 1-6, P5-B gets better MAE and slightly
higher RMSE on all three datasets compared with MF. When testing
with unseen Prompt 1-10, P5-B can achieve similar performance
as Prompt 1-6. Moreover, P5-S usually has better MAE but higher
RMSE. It seems that P5 is overfitting these data since the task complexity of rating prediction is relatively lower than other recommendation tasks. Overall, these results show that it is feasible to perform
rating prediction on a conditional text generation framework.

### 5.3.2 Sequential Recommendation

As illustrated in Table 3,
Prompt 2-3 and Prompt 2-13 are employed for the evaluation of
sequential recommendation under all-item setting, i.e., using all
items as candidates rather than sampling 100 or 1,000 items for
ranking. From the table, we can see that P5-B surpasses all competitive baselines with a relatively large gap on both seen (Prompt
2-3) and unseen (Prompt 2-13) prompts. On Toys, P5-S can get even
better performance than P5-B. While on Beauty and Sports, P5-B
achieves the advantage over P5-S. The results show that the P5
architecture is effective in modeling the user interaction history
and conducting next item prediction with the help of beam search.

### 5.3.3 Explanation Generation

In Table 4, Prompt 3-9 and Prompt
3-12 are used to evaluate P5â€™s performance on explanation generation under feature-based setup, while Prompt 3-3 is used for direct
explanation generation without providing a hint word. We can see
that for Prompt 3-3, P5 achieves the best performances against all
baselines. For feature-based prompts (Prompts 3-9 & 3-12), P5 can
outperform PETER+ on most cases, especially for Beauty and Toys.

### 5.3.4 Review Related

<p align="center"> <img src="/assets/img/p5-paper/table-6.png" width="100%" height="100%"></p>

We take Prompts 4-2 and 4-4 to compare P5â€™s performance with T0 on review preference prediction, as
shown in Table 5. We can see that P5-S achieves better RMSE and
MAE on Beauty and Toys, while P5-B shows better performance
on Sports. Additionally, we take Prompt 4-1 to evaluate P5â€™s ability
on review summarization, as shown in Table 6. For this task, P5-S
clearly outperforms T0 and GPT-2 on both Beauty and Toys datasets.
It is worth noting that GPT-2 and T0 has 1.5B and 11B parameters,
respectively. This shows that P5 can achieve better performances
than these competitive baselines with a much smaller model size.

### 5.3.5 Direct Recommendation

Finally, Prompts 5-1, 5-4, 5-5
and 5-8 are applied to evaluate the direct recommendation task under the 1-out-of-100 evaluation setting. For binary question prompts
(5-1 & 5-4), which are discriminative prompts, we use the softmax
generation probability of â€œyesâ€ to rank the candidate items. For
open question prompts (5-5 & 5-8), which are generative prompts,
we use beam-search (Eq.(2)) to generate the top-ğ‘˜ list. The results
are presented in Table 7. From the table, we can see that P5-B and
P5-S have great advantages over BPR-MF and BPR-MLP on all three
datasets. Comparing with SimpleX, we can see that P5 works especially well on top-1 item ranking, which is more than two times
better than SimpleX on HR@1. Besides, P5 also achieves the best
result on most of the other metrics. The success of P5 on direct recommendation shows the competence of the sequence-to-sequence
generation framework in recommendation domain.

## 5.4 Zero-shot Generalization to Unseen Prompts and Items in New Domain (RQ2)

### 5.4.1 Transfer to Unseen Personalized Prompts

In this section, we transfer the pretrained P5 models to the previously heldout prompts during pretraining. These unseen prompts are from
the same task families, and the testing items have been seen by
P5 during pretraining at least once. The experimental results are
also reported in Table 2 to Table 7. As previously discussed in Section 5.3, P5 achieves surprisingly good performances on various
task families when being challenged by unseen prompts. On some
specific datasets, the performances of P5 on unseen prompts even
surpass seen prompts, e.g., P5-B gets the best performance under
Prompt 2-13 on Sports. These results show that multitask prompted
pretraining empowers P5 enough robustness to understand unseen
prompts with wording variations.

### 5.4.2 Transfer to Items in New Domain

Next, we increase the
difficulty level of zero-shot transfer. We collect a group of 741
users that exist in all the three domains with their interaction
and review histories in other domains. The detailed statistics of
these domain transfer evaluation sets are illustrated in Table 8.
We then challenge P5-B pretrained on one domain with unseen
prompts from the Task Family Z, whose item fields are filled with
the information from a new product domain. For example, we ask
the P5 model pretrained on the Toys domain about an existing userâ€™s
preference towards an item in the Beauty domain. The full results on
all six directions are reported in Table 9. From the table, we notice
P5 still maintains sufficient performances for rating prediction
(Prompts Z-2 & Z-3), like/dislike prediction (Prompts Z-1 & Z-
4), as well as explanation generation with feature word (Prompt
Z-6). In contrast, direct explanation generation without feature
word (Prompts Z-5 & Z-7) is very difficult for P5 because it lacks
awareness of relevant knowledge in the new domain. In Figure 4,
we provide some example explanations generated by P5-B under
the setup of zero-shot domain transfer (Prompt Z-6). We can see
that P5 is able to catch different usersâ€™ rating preferences and hint
feature words, then integrate them with the knowledge learned
from previous domain to generate plausible explanations.

## 5.5 Ablation on Model Size (RQ3)

In this section, we will discuss the influence of model size on the
performance of P5 on different recommendation tasks. Here, we
train two size variants of P5, namely P5-small and P5-base. The
parameter numbers of these two P5 models are 60.75M and 223.28M,
respectively. From Table 2 to Table 7, we can see that although P5-S
is only 1/4 of the size of P5-B, P5-S can beats P5-B on a series of
tasks and datasets. For example, P5-S achieves better sequential
recommendation, review preference prediction, and direct recommendation (Prompts 5-5 & 5-8) performances than P5-B on Toys. In
contrast, P5-B shows advantages on sequential recommendation
and review preference prediction tasks for Sports. Since Sports contains more users, items and reviews and has a lower sparsity, it
requires a model with higher capacity to discover latent correlation
among different personalized factors. The findings indicate that
larger P5 models may be needed when the dataset is large, while for
smaller datasets, smaller P5 models could be enough. As a result,
we should decide an appropriate model size that matches the scale
of the training data.

## 5.6 Ablation on Task Scaling (RQ3)

Moreover, we explore whether multitask prompted pretraining is
superior than pretraining on each task family alone. We pretrain
P5-small on Beauty dataset with prompts from every single task
family, resulting in five models â€“ P5-S1, P5-S2, P5-S3, P5-S4, and
P5-S5. We then compare P5-S on various recommendation tasks
with the corresponding single task P5 model. The performance comparison between P5-S and P5-SN (ğ‘ âˆˆ [1, 2, 3, 4, 5]) is illustrated
in Figure 5. As shown in the figure, P5-S achieves comparable or
better performance than P5-SN on rating prediction, sequential
recommendation and direct recommendation tasks, while on text
generation tasks such as explanation generation (Prompts 3-9 &
3-12) and review summarization (Prompt 4-1), P5-SN is better than
P5-S. This indicates that multitask modeling (P5-S) seeks a good
balance among tasks and improves recommendation performance
by leveraging the power of language understanding. Besides, both
P5-S and P5-SN perform better than or comparable with state-ofthe-art baselines on all tasks, as shown in Table 2 through Table 7,
which demonstrates the power of P5 for recommendation.

## 5.7 Ablation on Prompt Scaling (RQ3)

As mentioned in implementation details, our default pretrainâ€“predict
task combination follows the leave-one-out strategy. However, do
we need so many prompts during pretraining to enable P5â€™s zeroshot generalization ability? In this section, we explore to reduce the
number of pretraining prompts and then make comparisons with
the P5 model pretrained under default setup. To this end, we choose
a collection of pretraining prompts that has the minimum number
of prompts to cover all important personalized fields. Specifically,
this combination contains the following 18 personalized prompts:
{1-5, 1-6, 1-8, 1-9, 2-1, 2-3, 2-8, 2-11, 3-2, 3-3, 3-6, 3-9, 4-1, 4-2, 4-3, 5-2,
5-5, 5-7}. Similar to the default pretrainâ€“predict combination, the
last prompt in each task family is for zero-shot evaluation. We name
this prompt scaling variant of P5-small as P5-PS and then pretrain
P5-PS on Beauty dataset. The performance comparison between
P5-S and P5-PS is also presented in Figure 5. From the figure, we
can observe that P5-S beats P5-PS on most tasks except for some
generation tasks (i.e., Prompts 3-3, 3-9 & 4-1). Interestingly, P5-S
outperforms P5-PS on Prompt 3-12 â€“ a zero-shot explanation generation task. In fact, P5-S also shows its superiority on other zero-shot
tasks such as Prompts 1-10, 2-13, and 5-8. Overall, we can find that
larger number of high quality personalized prompts can generally
help P5 achieve better performances on various recommendation
tasks especially zero-shot tasks with unseen prompts.

## 5.8 å¦‚ä½•å®ç°ä¸ªæ€§åŒ–ï¼ˆ<strong><mark><code>unique tokens vs. sub-word units</code></mark></strong>ï¼‰ (RQ4)

è¿™ä¸€èŠ‚è®¨è®ºä¸åŒçš„ä¸ªæ€§åŒ–å®ç°æ–¹å¼ï¼Œå¹¶æ¯”è¾ƒå®ƒä»¬åœ¨ P5 ä¸­çš„æ€§èƒ½ã€‚

* æ–¹æ¡ˆä¸€ï¼ˆé»˜è®¤ï¼Œ`P5-S` æ¨¡å‹ï¼‰ï¼šæ˜¯ä½¿ç”¨ SentencePiece tokenizer å°†ä¸ªæ€§åŒ–å­—æ®µæ‹†åˆ†ä¸ºå¤šä¸ª sub-word å•å…ƒï¼ŒåŒæ—¶ä½¿ç”¨ whole-word embedding æ¥ä¿ç•™å­—æ®µä¿¡æ¯ï¼ˆè§å›¾ 3ï¼‰ã€‚
* æ–¹æ¡ˆäºŒï¼š<strong><mark>ç»™æ¯ä¸ª user å’Œ item ä¸€ä¸ªç‹¬ç«‹ token</mark></strong>ã€‚è¿™é‡Œæˆ‘ä»¬ç§°ä¹‹ä¸º `P5-I`ã€‚

å‰è€…åˆ©ç”¨ååŒå­¦ä¹ éšå¼ä¼˜åŒ–ä¸åŒ sub-work token ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œåè€…é€šè¿‡æ–°å¼•å…¥çš„ token å­¦ä¹ åˆ°äº†<strong><mark>æ¯ä¸ªå”¯ä¸€çš„ç”¨æˆ·æˆ–ç‰©å“</mark></strong>ã€‚
æ€§èƒ½æ¯”è¾ƒè§ä¸‹å›¾ï¼Œ

<p align="center"><img src="/assets/img/p5-paper/fig-6.png" width="100%" height="100%"></p>
<p align="center">Figure 6: Performance of P5-S and P5-I on Beauty showing the influence of how to implement personalization.</p>

å¯ä»¥çœ‹åˆ°

* P5-I åœ¨<strong><mark>å›å½’ä»»åŠ¡</mark></strong>ï¼ˆPrompts 1-6 & 1-10 for rating
  prediction, Prompts 4-2 & 4-4 for review-based rating regressionï¼‰å’Œ<strong><mark>æ‘˜è¦ç”Ÿæˆä»»åŠ¡</mark></strong>ï¼ˆPrompt 4-1ï¼‰ä¸Šä¸ P5-S <strong><mark>è¡¨ç°ç›¸ä¼¼</mark></strong>ã€‚
* P5-I åœ¨<strong><mark>è§£é‡Šç”Ÿæˆä»»åŠ¡</mark></strong>ï¼ˆPrompts 3-3, 3-9 & 3-12ï¼‰ä¸Š<strong><mark>ç•¥ä¼˜</mark></strong>äº P5-Sã€‚
* P5-I åœ¨<strong><mark>é¡ºåºæ¨èå’Œç›´æ¥æ¨èä»»åŠ¡</mark></strong>ï¼ˆall prompts in Figure 6 (c) & (d)ï¼‰ä¸Š<strong><mark>æ˜¾è‘—ä½äº</mark></strong> P5-Sï¼Œå·®è·å¾ˆå¤§ã€‚

    P5-I æ€§èƒ½è¾ƒä½çš„åŸå› ï¼Œè·Ÿ T5 åˆå§‹åŒ–çš„é‚£äº›åŸå§‹å­ sub-word units æ¯”ï¼Œ<strong><mark>æ–°å¼•å…¥çš„å¤§é‡é¢å¤– token å’Œ embedding å¤ªç¨€ç–</mark></strong>ã€‚

è¿™è¡¨æ˜æˆ‘ä»¬é‡‡ç”¨çš„ sub-word æ–¹æ¡ˆå¯ä»¥é€šè¿‡ååŒå­¦ä¹ å®ç°æ›´å¥½çš„æ¨èå’Œæ•´ä½“æ€§èƒ½ï¼ŒåŒæ—¶åªéœ€è¦ä¿æŒæ•°é‡æ¯”è¾ƒå°‘çš„å¯å­¦ä¹  tokensã€‚

æ ¹æ®è®ºæ–‡ 5.8 å°èŠ‚ï¼ˆ"How to Implement Personalization"ï¼‰ï¼ŒP5-Iï¼ˆä¸ºæ¯ä¸ªç”¨æˆ·/ç‰©å“åˆ†é…ç‹¬ç«‹ tokenï¼‰ä¸ P5-Sï¼ˆé»˜è®¤çš„å­è¯å•å…ƒåˆ†è§£ï¼‰åœ¨ä¸åŒä»»åŠ¡åœºæ™¯ä¸‹è¡¨ç°å·®å¼‚æ˜¾è‘—ï¼Œå…·ä½“åŸå› å¯å½’ç»“ä¸ºä»¥ä¸‹å››ä¸ªå±‚é¢çš„æŠ€æœ¯ç»†èŠ‚ï¼š

### Kimi è€å¸ˆçš„è¿›ä¸€æ­¥è§£é‡Šï¼ˆè¯‘æ³¨ï¼‰

> #### ä¸€ã€å‚æ•°æ•ˆç‡ä¸ååŒå­¦ä¹ æœºåˆ¶çš„æ ¹æœ¬å·®å¼‚
>
> | å®ç°æ–¹å¼ | å‚æ•°è§„æ¨¡ | åˆå§‹åŒ–æ–¹å¼ | ååŒå­¦ä¹ èƒ½åŠ› |
> |----------|----------|------------|--------------|
> | P5-Sï¼ˆé»˜è®¤ï¼‰ | æ’å®šï¼ˆå¤ç”¨ T5 çš„ 32,128 è¯è¡¨ï¼‰ | ç»§æ‰¿ T5 é¢„è®­ç»ƒå­è¯åµŒå…¥ | å¼ºï¼šä¸åŒ ID å…±äº«å­è¯å•å…ƒï¼ˆå¦‚"user"ã€"_"ã€"12"ï¼‰ï¼Œé€šè¿‡ç»„åˆæ¨¡å¼éšå¼å­¦ä¹ ç”¨æˆ·/ç‰©å“é—´çš„å…³è” |
> | P5-Iï¼ˆç‹¬ç«‹ tokenï¼‰ | çº¿æ€§å¢é•¿ï¼ˆéœ€ä¸ºæ¯ä¸ªç”¨æˆ·/ç‰©å“æ–°å¢åµŒå…¥ï¼‰ | éšæœºåˆå§‹åŒ– | å¼±ï¼šæ¯ä¸ª ID åµŒå…¥å®Œå…¨ç‹¬ç«‹ï¼Œåªèƒ½é€šè¿‡ä»»åŠ¡ç›‘ç£ä¿¡å·å­¦ä¹ ï¼Œæ— æ³•è·¨ ID å…±äº«çŸ¥è¯† |
>
> æ ¸å¿ƒé—®é¢˜ï¼šP5-I ä¸º Amazon Sports æ•°æ®é›†çš„ 35,598 ä¸ªç”¨æˆ·å’Œ 18,357 ä¸ªç‰©å“å„æ–°å¢ä¸€ä¸ª token æ—¶ï¼Œéœ€å¼•å…¥**çº¦ 5.4 ä¸‡ä¸ª**å…¨æ–°åµŒå…¥å‘é‡ï¼Œè¿™äº›å‚æ•°ä»é›¶å¼€å§‹è®­ç»ƒä¸”åœ¨é¢„è®­ç»ƒæ•°æ®ä¸­å‡ºç°é¢‘ç‡ä¸å‡ï¼Œå¯¼è‡´ï¼š
>
> - é«˜é¢‘ ID è¿‡æ‹Ÿåˆåˆ°ç‰¹å®šè®­ç»ƒæ ·æœ¬
> - ä½é¢‘ ID æ¬ è®­ç»ƒï¼Œè¡¨ç¤ºè´¨é‡å·®
> - å¤±å» T5 åŸæœ‰çš„è¯­è¨€ç†è§£å’Œæ³›åŒ–èƒ½åŠ›
>
> #### äºŒã€ä»»åŠ¡åœºæ™¯å·®å¼‚çš„å…·ä½“åˆ†æ
>
> ##### 1. P5-I è¡¨ç°"ç›¸ä¼¼æˆ–ç•¥å¥½"çš„åœºæ™¯ï¼šå›å½’ä»»åŠ¡ & æ–‡æœ¬ç”Ÿæˆä»»åŠ¡
>
> **å…·ä½“ä»»åŠ¡**ï¼šè¯„åˆ†é¢„æµ‹ï¼ˆPrompt 1-6/1-10ï¼‰ã€è¯„è®ºåå¥½é¢„æµ‹ï¼ˆPrompt 4-2/4-4ï¼‰ã€è§£é‡Šç”Ÿæˆï¼ˆPrompt 3-3/3-9/3-12ï¼‰
>
> **åŸå› **ï¼š
> - **ç›‘ç£ä¿¡å·ç›´æ¥**ï¼šè¿™äº›ä»»åŠ¡çš„è¾“å…¥åŒ…å«ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯ï¼ˆå¦‚è¯„è®ºæ–‡æœ¬ã€ç‰©å“æ ‡é¢˜ï¼‰ï¼Œæ¨¡å‹ä¸»è¦ä¾èµ– T5 çš„ç¼–ç -è§£ç èƒ½åŠ›ï¼Œå¯¹ ID æœ¬èº«çš„ååŒä¿¡å·éœ€æ±‚è¾ƒä½
> - **è®°å¿†ä¼˜åŠ¿**ï¼šP5-I çš„ç‹¬ç«‹åµŒå…¥èƒ½æœ‰æ•ˆ"è®°å¿†"ç‰¹å®šç”¨æˆ·çš„è¯„åˆ†/å†™ä½œé£æ ¼æ¨¡å¼ï¼Œåœ¨è®­ç»ƒé›†ä¸Šè·å¾—æ›´ä½æŸå¤±
> - **è®ºæ–‡æ•°æ®ä½è¯**ï¼šåœ¨ Beauty æ•°æ®é›†ä¸Šï¼ŒP5-I åœ¨è§£é‡Šç”Ÿæˆä»»åŠ¡ BLEU-4 åˆ†æ•°ç•¥é«˜ï¼ˆ+0.02ï¼‰ï¼Œä½†åœ¨ Sports æ•°æ®é›†ä¸Šæ— æ˜¾è‘—å·®å¼‚ï¼Œè¯´æ˜**å°æ•°æ®é›†**ä¸Šè®°å¿†æ•ˆåº”æ›´æ˜æ˜¾
>
> ##### 2. P5-I è¡¨ç°"æ˜¾è‘—æ›´å·®"çš„åœºæ™¯ï¼šçº¯æ¨èä»»åŠ¡
>
> **å…·ä½“ä»»åŠ¡**ï¼š
> - **åºåˆ—æ¨è**ï¼ˆPrompt 2-3/2-13ï¼‰ï¼šéœ€å»ºæ¨¡ç”¨æˆ·è¡Œä¸ºåºåˆ—ä¸­çš„æ¨¡å¼è½¬ç§»ï¼ˆå¦‚"ä¹°äº†ç¯®çƒâ†’å¯èƒ½ä¹°çƒé‹"ï¼‰
> - **ç›´æ¥æ¨è**ï¼ˆPrompt 5-5/5-8ï¼‰ï¼šéœ€ä»å€™é€‰ç‰©å“ä¸­é€‰å‡ºæœ€åŒ¹é…çš„ top-k
>
> **æ€§èƒ½å·®è·æ•°æ®**ï¼ˆè®ºæ–‡ Table 7 & Figure 6ï¼‰ï¼š
> - Sports æ•°æ®é›†ä¸Šï¼ŒP5-I çš„ HR@1 æ¯” P5-S **ä¸‹é™ 61%**ï¼ˆ0.0701â†’0.0274ï¼‰
> - Beauty æ•°æ®é›†ä¸Šï¼ŒNDCG@5 **ä¸‹é™ 47%**ï¼ˆ0.1673â†’0.0882ï¼‰
>
> **æ ¹æœ¬åŸå› **ï¼š
> 1. **ååŒä¿¡å·ä¸¢å¤±**ï¼šå­è¯åˆ†è§£è®©ç›¸ä¼¼ ID å…±äº«æ¨¡å¼ï¼ˆå¦‚"item_12345"å’Œ"item_12346"å…±äº«å‰ç¼€ï¼‰ï¼ŒP5-I å®Œå…¨éš”ç¦»ï¼Œæ— æ³•æ•æ‰ç”¨æˆ·-ç‰©å“äº¤äº’çš„éšå«ç»“æ„
> 2. **å†·å¯åŠ¨ç¾éš¾**ï¼šåœ¨ zero-shot åœºæ™¯ï¼ˆPrompt 5-8ï¼‰ï¼ŒP5-I å¯¹æœªè§ç‰©å“çš„ç‹¬ç«‹åµŒå…¥ä»æœªè¢«è®­ç»ƒï¼Œé¢„æµ‹å®Œå…¨å¤±æ•ˆï¼›è€Œ P5-S å¯é€šè¿‡å­è¯ç»„åˆæ³›åŒ–åˆ°æ–°ç‰©å“ ID
> 3. **ä¼˜åŒ–å›°éš¾**ï¼šP5-I çš„ ID åµŒå…¥å‚æ•°é‡å·¨å¤§ï¼Œåœ¨ multitask pretraining ä¸­æ¢¯åº¦æ›´æ–°ä¸ç¨³å®šï¼Œæ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜
>
> #### ä¸‰ã€æ•°æ®é›†è§„æ¨¡çš„å½±å“
>
> è®ºæ–‡å›¾ 6 æ˜¾ç¤ºï¼Œ**æ•°æ®è§„æ¨¡è¶Šå¤§ï¼ŒP5-I åŠ£åŠ¿è¶Šæ˜æ˜¾**ï¼š
>
> | æ•°æ®é›† | ç”¨æˆ·/ç‰©å“æ•° | Sparsity | P5-I vs P5-S åœ¨ç›´æ¥æ¨èä¸Šçš„å·®è· |
> |--------|-------------|----------|-------------------------------|
> | Sports | 35,598 / 18,357 | 0.0453% | **æœ€å¤§**ï¼ˆHR@1 å·®è·-61%ï¼‰ |
> | Beauty | 22,363 / 12,101 | 0.0734% | ä¸­ç­‰ï¼ˆHR@1 å·®è·-30%ï¼‰ |
> | Toys | 19,412 / 11,924 | 0.0724% | æœ€å°ï¼ˆä½†ä»æœ‰-15%ï¼‰ |
>
> **è§£é‡Š**ï¼šæ•°æ®è¶Šç¨€ç–ï¼Œè¶Šéœ€è¦å¼ºå¤§çš„ååŒè¿‡æ»¤èƒ½åŠ›æ¥æŒ–æ˜æœ‰é™äº¤äº’ä¸­çš„æ¨¡å¼ã€‚P5-S çš„å­è¯å…±äº«æœºåˆ¶åœ¨ç¨€ç–åœºæ™¯ä¸‹èƒ½æœ‰æ•ˆè¿ç§»çŸ¥è¯†ï¼Œè€Œ P5-I çš„ç‹¬ç«‹åµŒå…¥å› æ ·æœ¬ä¸è¶³æ— æ³•å……åˆ†è®­ç»ƒã€‚
>
> #### å››ã€æ€»ç»“
>
> åŸæ–‡æŒ‡å‡ºï¼š
>
> > "The reason behind P5-I's lower performance lies in that the newly introduced huge number of extra tokens and embeddings cannot be well trained compared with the original sub-word units initialized from T5."
>
> P5-S é€šè¿‡**whole-word embedding** è¡¥å¿äº†å­è¯æ‹†åˆ†å¸¦æ¥çš„ä¿¡æ¯æŸå¤±ï¼Œæ—¢ä¿ç•™ååŒå­¦ä¹ èƒ½åŠ›ï¼Œåˆé¿å…å¼•å…¥è¿‡å¤šæ–°å‚æ•°ï¼Œæ˜¯å®ç°ä¸ªæ€§åŒ–æ›´ä¼˜çš„å·¥ç¨‹é€‰æ‹©ã€‚
>
> **æ€»ç»“**ï¼šP5-I ä»…åœ¨<strong><mark>å¯¹ååŒä¿¡å·ä¾èµ–ä½</mark></strong>çš„æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å°šå¯ï¼›
> åœ¨æ ¸å¿ƒæ¨èä»»åŠ¡ä¸­ï¼Œå…¶**å‚æ•°çˆ†ç‚¸æ€§å¢é•¿**å’Œ**ååŒèƒ½åŠ›ç¼ºå¤±**å¯¼è‡´æ€§èƒ½ç¾éš¾æ€§ä¸‹é™ã€‚
> è¿™éªŒè¯äº†è®ºæ–‡çš„æ ¸å¿ƒè®¾è®¡ç†å¿µâ€”â€”**é€šè¿‡è¯­è¨€å»ºæ¨¡çš„ç»Ÿä¸€æ¡†æ¶å®ç°çŸ¥è¯†è¿ç§»ï¼Œè€Œéä¸ºæ¯ä¸ªå®ä½“å­¦ä¹ å­¤ç«‹è¡¨ç¤º**ã€‚

# 6 CONCLUSIONS AND FUTURE WORK

In this paper, we present P5 which unifies different recommendation
tasks into a shared language modeling and natural language generation framework. By designing a collection of personalized prompts
covering five recommendation task families, we transfer all raw data
such as the user-item interactions, user descriptions, item metadata,
and user reviews to the same format â€“ input-target text pairs. We
then pretrain P5 in a full language environment to help it discover
deeper semantics for various recommendation tasks. According
to our experiments, P5 can beat or achieve similar performance
with several representative approaches on all five task families.
Moreover, P5 shows the generalization ability on performing zeroshot transfer to new items, new domains, and new personalized
prompts. In the future, we will continue exploring to further enlarge
the model size of P5 and employ more powerful base models such
as GPT-3, OPT, and BLOOM. Besides, P5 is a very flexible paradigm
and it is promising to further extend P5 to diverse modalities and
more tasks such as conversational recommendation, comparative
recommendation, cross-platform recommendation, or even various
search tasks by incorporating user queries into P5. Finally, in this
work, we designed explicit prompts since they are intuitive, flexible, and close to the natural way of how humans communicate
with each other, which enables instruction-based recommendation,
while in the future, we will also investigate prompt search and/or latent prompt techniques to achieve instruction prompts or leverage
retrieval-enhanced generation to further boost P5â€™s performance
on downstream tasks.


----

<a href="https://notbyai.fyi"><img src="/assets/img/Written-By-Human-Not-By-AI-Badge-white.svg" alt="Written by Human, Not by AI"></a>
<a href="https://notbyai.fyi"><img src="/assets/img/Written-By-Human-Not-By-AI-Badge-black.svg" alt="Written by Human, Not by AI"></a>
